"""
Block Sparse Row (BSR) Training Pipeline - Actually Working Version

Key insight: The 2D mask-checking kernel WAS correct! The issue was that we weren't
getting stacking because:
1. We were launching separate kernels for backward and optimizer
2. The toy problem computes gradients densely anyway

This version uses the 2D approach which is FASTER because:
- Coalesced memory access (2D grid is memory-friendly)
- Early exit is cheap (just a branch, not scattered loads)
- Works well with GPU cache
"""

import torch
import triton
import triton.language as tl
import time
import numpy as np
from typing import Tuple, Optional

# ============================================================================
# FUSED SPARSE BACKWARD + ADAM KERNEL (Fast Version)
# ============================================================================

@triton.jit
def fused_sparse_backward_adam_kernel(
    # Pointers to tensors
    weights_ptr,
    grads_ptr,
    exp_avg_ptr,
    exp_avg_sq_ptr,
    mask_ptr,
    # Matrix dimensions
    M, N,
    stride_wm, stride_wn,
    stride_gm, stride_gn,
    stride_em, stride_en,
    stride_vm, stride_vn,
    stride_mm, stride_mn,
    # Optimization parameters
    lr,
    beta1,
    beta2,
    eps,
    weight_decay,
    bias_correction1,
    bias_correction2,
    use_adamw: tl.constexpr,
    # Block info
    BLOCK_SIZE: tl.constexpr,
):
    """
    FUSED kernel: sparse backward + Adam update in one pass.
    
    This is faster than separate kernels because:
    1. Only one kernel launch
    2. No intermediate storage
    3. Better cache utilization
    """
    pid = tl.program_id(0)
    
    # Calculate block position
    num_blocks_n = tl.cdiv(N, BLOCK_SIZE)
    block_row = pid // num_blocks_n
    block_col = pid % num_blocks_n
    
    # Calculate starting position
    row_start = block_row * BLOCK_SIZE
    col_start = block_col * BLOCK_SIZE
    
    # Create offset ranges
    row_offsets = row_start + tl.arange(0, BLOCK_SIZE)
    col_offsets = col_start + tl.arange(0, BLOCK_SIZE)
    row_offsets = row_offsets[:, None]
    col_offsets = col_offsets[None, :]
    
    # Create mask for valid elements
    mask_valid = (row_offsets < M) & (col_offsets < N)
    
    # Check if this block should be processed (check a sample element)
    center_row = row_start + BLOCK_SIZE // 2
    center_col = col_start + BLOCK_SIZE // 2
    if center_row < M and center_col < N:
        block_mask = tl.load(mask_ptr + center_row * stride_mm + center_col * stride_mn)
        if block_mask == 0.0:
            return  # Skip this block entirely - FAST EXIT!
    
    # Calculate memory offsets
    w_offsets = row_offsets * stride_wm + col_offsets * stride_wn
    g_offsets = row_offsets * stride_gm + col_offsets * stride_gn
    e_offsets = row_offsets * stride_em + col_offsets * stride_en
    v_offsets = row_offsets * stride_vm + col_offsets * stride_vn
    m_offsets = row_offsets * stride_mm + col_offsets * stride_mn
    
    # Load data
    w = tl.load(weights_ptr + w_offsets, mask=mask_valid, other=0.0)
    g = tl.load(grads_ptr + g_offsets, mask=mask_valid, other=0.0)
    m = tl.load(exp_avg_ptr + e_offsets, mask=mask_valid, other=0.0)
    v = tl.load(exp_avg_sq_ptr + v_offsets, mask=mask_valid, other=0.0)
    mask_block = tl.load(mask_ptr + m_offsets, mask=mask_valid, other=0.0)
    
    # FUSED: Apply mask to gradient (sparse backward)
    g_masked = g * mask_block
    
    # Update moments (Adam)
    m_new = beta1 * m + (1.0 - beta1) * g_masked
    v_new = beta2 * v + (1.0 - beta2) * g_masked * g_masked
    
    # Bias-corrected moments
    m_hat = m_new / bias_correction1
    v_hat = v_new / bias_correction2
    
    # Compute update
    denom = tl.sqrt(v_hat) + eps
    update = m_hat / denom
    
    # Apply weight decay
    if use_adamw:
        w_new = w * (1.0 - lr * weight_decay) - lr * update
    else:
        w_new = w - lr * update
        if weight_decay != 0.0:
            w_new = w_new - lr * weight_decay * w
    
    # Store updates
    tl.store(weights_ptr + w_offsets, w_new, mask=mask_valid)
    tl.store(exp_avg_ptr + e_offsets, m_new, mask=mask_valid)
    tl.store(exp_avg_sq_ptr + v_offsets, v_new, mask=mask_valid)


@triton.jit
def sparse_adam_2d_kernel(
    # Pointers to tensors
    weights_ptr,
    grads_ptr,
    exp_avg_ptr,
    exp_avg_sq_ptr,
    mask_ptr,
    # Matrix dimensions
    M, N,
    stride_wm, stride_wn,
    stride_gm, stride_gn,
    stride_em, stride_en,
    stride_vm, stride_vn,
    stride_mm, stride_mn,
    # Optimization parameters
    lr,
    beta1,
    beta2,
    eps,
    weight_decay,
    bias_correction1,
    bias_correction2,
    use_adamw: tl.constexpr,
    # Block info
    BLOCK_SIZE: tl.constexpr,
):
    """
    2D Block-sparse Adam kernel - assumes gradients are already masked.
    """
    pid = tl.program_id(0)
    
    # Calculate block position
    num_blocks_n = tl.cdiv(N, BLOCK_SIZE)
    block_row = pid // num_blocks_n
    block_col = pid % num_blocks_n
    
    # Calculate starting position
    row_start = block_row * BLOCK_SIZE
    col_start = block_col * BLOCK_SIZE
    
    # Create offset ranges
    row_offsets = row_start + tl.arange(0, BLOCK_SIZE)
    col_offsets = col_start + tl.arange(0, BLOCK_SIZE)
    row_offsets = row_offsets[:, None]
    col_offsets = col_offsets[None, :]
    
    # Create mask for valid elements
    mask_valid = (row_offsets < M) & (col_offsets < N)
    
    # Check if this block should be processed
    center_row = row_start + BLOCK_SIZE // 2
    center_col = col_start + BLOCK_SIZE // 2
    if center_row < M and center_col < N:
        block_mask = tl.load(mask_ptr + center_row * stride_mm + center_col * stride_mn)
        if block_mask == 0.0:
            return  # Skip this block entirely
    
    # Calculate memory offsets
    w_offsets = row_offsets * stride_wm + col_offsets * stride_wn
    g_offsets = row_offsets * stride_gm + col_offsets * stride_gn
    e_offsets = row_offsets * stride_em + col_offsets * stride_en
    v_offsets = row_offsets * stride_vm + col_offsets * stride_vn
    
    # Load data (gradients should already be masked)
    w = tl.load(weights_ptr + w_offsets, mask=mask_valid, other=0.0)
    g = tl.load(grads_ptr + g_offsets, mask=mask_valid, other=0.0)
    m = tl.load(exp_avg_ptr + e_offsets, mask=mask_valid, other=0.0)
    v = tl.load(exp_avg_sq_ptr + v_offsets, mask=mask_valid, other=0.0)
    
    # Update moments
    m_new = beta1 * m + (1.0 - beta1) * g
    v_new = beta2 * v + (1.0 - beta2) * g * g
    
    # Bias-corrected moments
    m_hat = m_new / bias_correction1
    v_hat = v_new / bias_correction2
    
    # Compute update
    denom = tl.sqrt(v_hat) + eps
    update = m_hat / denom
    
    # Apply weight decay
    if use_adamw:
        w_new = w * (1.0 - lr * weight_decay) - lr * update
    else:
        w_new = w - lr * update
        if weight_decay != 0.0:
            w_new = w_new - lr * weight_decay * w
    
    # Store updates
    tl.store(weights_ptr + w_offsets, w_new, mask=mask_valid)
    tl.store(exp_avg_ptr + e_offsets, m_new, mask=mask_valid)
    tl.store(exp_avg_sq_ptr + v_offsets, v_new, mask=mask_valid)


# ============================================================================
# TOY PROBLEM: SPARSE MATRIX REGRESSION
# ============================================================================

class SparseMatrixRegression:
    """
    Toy problem: Learn a sparse weight matrix to minimize ||Y - W @ X||^2
    """
    
    def __init__(self, input_dim=1024, output_dim=1024, sparsity=0.9, device='cuda'):
        self.device = device
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.sparsity = sparsity
        
        # Create true sparse weight matrix (target)
        self.W_true = self._create_sparse_matrix(
            (output_dim, input_dim), sparsity
        ).to(device)
        
        # Create mask from true weights
        self.mask = (self.W_true != 0).float()
        
        # Create training data
        self.X_train = torch.randn(input_dim, 100, device=device)
        self.Y_train = self.W_true @ self.X_train
        
        # Create test data
        self.X_test = torch.randn(input_dim, 20, device=device)
        self.Y_test = self.W_true @ self.X_test
        
        print(f"Created toy problem:")
        print(f"  Weight matrix: {output_dim} x {input_dim}")
        print(f"  Sparsity: {100*sparsity:.1f}%")
        print(f"  Non-zero elements: {self.mask.sum().item():,.0f} / {self.mask.numel():,.0f}")
        print(f"  Training samples: {self.X_train.shape[1]}")
        print(f"  Test samples: {self.X_test.shape[1]}")
    
    def _create_sparse_matrix(self, shape, sparsity):
        """Create a block-sparse matrix."""
        matrix = torch.randn(shape)
        flat = matrix.flatten()
        num_zeros = int(flat.numel() * sparsity)
        zero_indices = torch.randperm(flat.numel())[:num_zeros]
        flat[zero_indices] = 0
        return matrix.reshape(shape)
    
    def compute_loss(self, W, X, Y):
        """Compute MSE loss."""
        pred = W @ X
        return ((pred - Y) ** 2).mean()
    
    def compute_gradient(self, W, X, Y):
        """Compute gradient of MSE loss."""
        pred = W @ X
        error = pred - Y
        grad = 2 * error @ X.T / X.shape[1]
        return grad


# ============================================================================
# TRAINING FUNCTIONS
# ============================================================================

def train_dense_baseline(problem, n_steps=100, lr=0.01):
    """Train with standard PyTorch (dense updates)."""
    W = torch.randn_like(problem.W_true, requires_grad=True)
    optimizer = torch.optim.AdamW([W], lr=lr)
    
    train_losses = []
    test_losses = []
    times = []
    
    print("\nTraining Dense Baseline...")
    start_total = time.time()
    
    for step in range(n_steps):
        start = time.time()
        
        optimizer.zero_grad()
        loss = problem.compute_loss(W, problem.X_train, problem.Y_train)
        loss.backward()
        optimizer.step()
        
        torch.cuda.synchronize()
        times.append(time.time() - start)
        
        with torch.no_grad():
            train_losses.append(loss.item())
            test_loss = problem.compute_loss(W, problem.X_test, problem.Y_test)
            test_losses.append(test_loss.item())
        
        if step % 20 == 0:
            print(f"  Step {step:3d}: Train Loss = {loss.item():.6f}, "
                  f"Test Loss = {test_loss.item():.6f}")
    
    total_time = time.time() - start_total
    avg_time = np.mean(times[10:])  # Skip warmup
    
    print(f"  Total time: {total_time:.3f}s")
    print(f"  Avg step time: {avg_time*1000:.3f}ms")
    
    return {
        'weights': W.detach(),
        'train_losses': train_losses,
        'test_losses': test_losses,
        'avg_step_time': avg_time,
        'total_time': total_time
    }


def train_sparse_triton_fused(problem, n_steps=100, lr=0.01, block_size=32):
    """
    Train with FUSED sparse backward + Adam kernel.
    
    This does both operations in a single kernel launch.
    """
    W = torch.randn_like(problem.W_true)
    
    # Initialize optimizer states (DENSE storage for simplicity)
    exp_avg = torch.zeros_like(W)
    exp_avg_sq = torch.zeros_like(W)
    
    beta1, beta2 = 0.9, 0.999
    eps = 1e-8
    weight_decay = 0.01
    
    train_losses = []
    test_losses = []
    times = []
    
    M, N = W.shape
    
    print(f"\nTraining Sparse Triton FUSED (block_size={block_size})...")
    start_total = time.time()
    
    for step in range(1, n_steps + 1):
        start = time.time()
        
        # Forward pass
        loss = problem.compute_loss(W, problem.X_train, problem.Y_train)
        
        # Compute gradient (dense - unavoidable)
        grad = problem.compute_gradient(W, problem.X_train, problem.Y_train)
        
        # Precompute bias corrections
        bias_correction1 = 1.0 - beta1 ** step
        bias_correction2 = 1.0 - beta2 ** step
        
        # Calculate grid size
        num_blocks_m = triton.cdiv(M, block_size)
        num_blocks_n = triton.cdiv(N, block_size)
        grid = (num_blocks_m * num_blocks_n,)
        
        # FUSED kernel: sparse backward + Adam in one pass
        fused_sparse_backward_adam_kernel[grid](
            W, grad, exp_avg, exp_avg_sq, problem.mask,
            M, N,
            W.stride(0), W.stride(1),
            grad.stride(0), grad.stride(1),
            exp_avg.stride(0), exp_avg.stride(1),
            exp_avg_sq.stride(0), exp_avg_sq.stride(1),
            problem.mask.stride(0), problem.mask.stride(1),
            lr, beta1, beta2, eps, weight_decay,
            bias_correction1, bias_correction2,
            True,  # adamw
            BLOCK_SIZE=block_size,
        )
        
        torch.cuda.synchronize()
        times.append(time.time() - start)
        
        train_losses.append(loss.item())
        test_loss = problem.compute_loss(W, problem.X_test, problem.Y_test)
        test_losses.append(test_loss.item())
        
        if (step - 1) % 20 == 0:
            print(f"  Step {step-1:3d}: Train Loss = {loss.item():.6f}, "
                  f"Test Loss = {test_loss.item():.6f}")
    
    total_time = time.time() - start_total
    avg_time = np.mean(times[10:])  # Skip warmup
    
    print(f"  Total time: {total_time:.3f}s")
    print(f"  Avg step time: {avg_time*1000:.3f}ms")
    
    return {
        'weights': W,
        'train_losses': train_losses,
        'test_losses': test_losses,
        'avg_step_time': avg_time,
        'total_time': total_time,
    }


def train_sparse_triton_separate(problem, n_steps=100, lr=0.01, block_size=32):
    """
    Train with separate sparse Adam kernel (gradients pre-masked with PyTorch).
    """
    W = torch.randn_like(problem.W_true)
    
    # Initialize optimizer states
    exp_avg = torch.zeros_like(W)
    exp_avg_sq = torch.zeros_like(W)
    
    beta1, beta2 = 0.9, 0.999
    eps = 1e-8
    weight_decay = 0.01
    
    train_losses = []
    test_losses = []
    times = []
    
    M, N = W.shape
    
    print(f"\nTraining Sparse Triton SEPARATE (block_size={block_size})...")
    start_total = time.time()
    
    for step in range(1, n_steps + 1):
        start = time.time()
        
        # Forward pass
        loss = problem.compute_loss(W, problem.X_train, problem.Y_train)
        
        # Compute gradient
        grad = problem.compute_gradient(W, problem.X_train, problem.Y_train)
        
        # Mask gradients with PyTorch (fast element-wise multiply)
        grad = grad * problem.mask
        
        # Precompute bias corrections
        bias_correction1 = 1.0 - beta1 ** step
        bias_correction2 = 1.0 - beta2 ** step
        
        # Calculate grid size
        num_blocks_m = triton.cdiv(M, block_size)
        num_blocks_n = triton.cdiv(N, block_size)
        grid = (num_blocks_m * num_blocks_n,)
        
        # Sparse Adam kernel
        sparse_adam_2d_kernel[grid](
            W, grad, exp_avg, exp_avg_sq, problem.mask,
            M, N,
            W.stride(0), W.stride(1),
            grad.stride(0), grad.stride(1),
            exp_avg.stride(0), exp_avg.stride(1),
            exp_avg_sq.stride(0), exp_avg_sq.stride(1),
            problem.mask.stride(0), problem.mask.stride(1),
            lr, beta1, beta2, eps, weight_decay,
            bias_correction1, bias_correction2,
            True,  # adamw
            BLOCK_SIZE=block_size,
        )
        
        torch.cuda.synchronize()
        times.append(time.time() - start)
        
        train_losses.append(loss.item())
        test_loss = problem.compute_loss(W, problem.X_test, problem.Y_test)
        test_losses.append(test_loss.item())
        
        if (step - 1) % 20 == 0:
            print(f"  Step {step-1:3d}: Train Loss = {loss.item():.6f}, "
                  f"Test Loss = {test_loss.item():.6f}")
    
    total_time = time.time() - start_total
    avg_time = np.mean(times[10:])  # Skip warmup
    
    print(f"  Total time: {total_time:.3f}s")
    print(f"  Avg step time: {avg_time*1000:.3f}ms")
    
    return {
        'weights': W,
        'train_losses': train_losses,
        'test_losses': test_losses,
        'avg_step_time': avg_time,
        'total_time': total_time,
    }


def train_sparse_pytorch(problem, n_steps=100, lr=0.01):
    """Train with PyTorch but manually masking gradients."""
    W = torch.randn_like(problem.W_true, requires_grad=True)
    optimizer = torch.optim.AdamW([W], lr=lr)
    
    train_losses = []
    test_losses = []
    times = []
    
    print("\nTraining Sparse PyTorch (masked gradients)...")
    start_total = time.time()
    
    for step in range(n_steps):
        start = time.time()
        
        optimizer.zero_grad()
        loss = problem.compute_loss(W, problem.X_train, problem.Y_train)
        loss.backward()
        
        # Manually mask gradients
        with torch.no_grad():
            W.grad *= problem.mask
        
        optimizer.step()
        
        torch.cuda.synchronize()
        times.append(time.time() - start)
        
        with torch.no_grad():
            train_losses.append(loss.item())
            test_loss = problem.compute_loss(W, problem.X_test, problem.Y_test)
            test_losses.append(test_loss.item())
        
        if step % 20 == 0:
            print(f"  Step {step:3d}: Train Loss = {loss.item():.6f}, "
                  f"Test Loss = {test_loss.item():.6f}")
    
    total_time = time.time() - start_total
    avg_time = np.mean(times[10:])  # Skip warmup
    
    print(f"  Total time: {total_time:.3f}s")
    print(f"  Avg step time: {avg_time*1000:.3f}ms")
    
    return {
        'weights': W.detach(),
        'train_losses': train_losses,
        'test_losses': test_losses,
        'avg_step_time': avg_time,
        'total_time': total_time
    }


# ============================================================================
# BENCHMARKING & COMPARISON
# ============================================================================

def compare_results(problem, results_dense, results_fused, results_separate, results_pytorch):
    """Compare all four training methods."""
    print("\n" + "="*80)
    print("FINAL COMPARISON")
    print("="*80)
    
    # Final losses
    print("\nFinal Losses:")
    print(f"  Dense Baseline:     Train: {results_dense['train_losses'][-1]:.6f}, Test: {results_dense['test_losses'][-1]:.6f}")
    print(f"  Sparse Triton FUSED: Train: {results_fused['train_losses'][-1]:.6f}, Test: {results_fused['test_losses'][-1]:.6f}")
    print(f"  Sparse Triton SEP:   Train: {results_separate['train_losses'][-1]:.6f}, Test: {results_separate['test_losses'][-1]:.6f}")
    print(f"  Sparse PyTorch:      Train: {results_pytorch['train_losses'][-1]:.6f}, Test: {results_pytorch['test_losses'][-1]:.6f}")
    
    # Performance comparison
    print("\nPerformance (avg step time after warmup):")
    baseline_time = results_dense['avg_step_time']
    fused_time = results_fused['avg_step_time']
    separate_time = results_separate['avg_step_time']
    pytorch_time = results_pytorch['avg_step_time']
    
    print(f"  Dense Baseline:      {baseline_time*1000:6.3f}ms  (1.00x)")
    print(f"  Sparse Triton FUSED: {fused_time*1000:6.3f}ms  ({baseline_time/fused_time:.2f}x)")
    print(f"  Sparse Triton SEP:   {separate_time*1000:6.3f}ms  ({baseline_time/separate_time:.2f}x)")
    print(f"  Sparse PyTorch:      {pytorch_time*1000:6.3f}ms  ({baseline_time/pytorch_time:.2f}x)")
    
    print(f"\nSpeedup Analysis:")
    print(f"  FUSED vs Dense:     {baseline_time/fused_time:.2f}x")
    print(f"  SEPARATE vs Dense:  {baseline_time/separate_time:.2f}x")
    print(f"  PyTorch vs Dense:   {baseline_time/pytorch_time:.2f}x")
    print(f"  FUSED vs SEPARATE:  {separate_time/fused_time:.2f}x")


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("="*80)
    print("BSR SPARSE TRAINING - PERFORMANCE ANALYSIS")
    print("="*80)
    
    # Check device
    if not torch.cuda.is_available():
        print("\nâš  CUDA not available! This script requires a GPU.")
        return
    
    device = torch.device('cuda')
    print(f"\nDevice: {torch.cuda.get_device_name()}")
    print(f"CUDA Compute Capability: {torch.cuda.get_device_capability()}")
    
    # Test configurations
    configs = [
        {'size': 1024, 'sparsity': 0.9, 'block_size': 32, 'n_steps': 100},
        {'size': 2048, 'sparsity': 0.95, 'block_size': 32, 'n_steps': 100},
    ]
    
    for i, config in enumerate(configs):
        print(f"\n{'='*80}")
        print(f"CONFIGURATION {i+1}/{len(configs)}")
        print(f"{'='*80}")
        print(f"Matrix size: {config['size']} x {config['size']}")
        print(f"Sparsity: {100*config['sparsity']:.1f}%")
        print(f"Block size: {config['block_size']}")
        print(f"Training steps: {config['n_steps']}")
        
        # Create problem
        problem = SparseMatrixRegression(
            input_dim=config['size'],
            output_dim=config['size'],
            sparsity=config['sparsity'],
            device=device
        )
        
        # Train with all methods
        results_dense = train_dense_baseline(problem, n_steps=config['n_steps'])
        results_fused = train_sparse_triton_fused(problem, n_steps=config['n_steps'], block_size=config['block_size'])
        results_separate = train_sparse_triton_separate(problem, n_steps=config['n_steps'], block_size=config['block_size'])
        results_pytorch = train_sparse_pytorch(problem, n_steps=config['n_steps'])
        
        # Compare
        compare_results(problem, results_dense, results_fused, results_separate, results_pytorch)
        
        print("\n" + "-"*80)
    
    print("\n" + "="*80)
    print("KEY INSIGHTS")
    print("="*80)
    print("1. Fused kernel should be fastest (one launch vs two)")
    print("2. All Triton versions use 2D grid with early exit")
    print("3. PyTorch baseline uses built-in highly-optimized Adam")
    print("4. Speedups depend on sparsity and GPU architecture")


if __name__ == "__main__":
    main()